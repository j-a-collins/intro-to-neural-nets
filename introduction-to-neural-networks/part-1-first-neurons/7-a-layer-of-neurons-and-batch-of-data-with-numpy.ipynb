{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLT: Introduction to Neural Networks\n",
    "## A Layer of Neurons and Batch of Data with NumPy\n",
    "###### J-A-Collins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get back to our inputs and weights — when covering them, we mentioned that we need to perform dot products on all of the vectors that consist of both input and weight matrices. As we have just learned, that’s the operation that the matrix product performs. We just need to perform transposition on its second argument, which is the weights matrix in our case, to turn the row vectors it currently consists of into column vectors.  \n",
    "\n",
    "\n",
    "Initially, we were able to perform the dot product on the inputs and the weights without a transposition because the weights were a matrix, but the inputs were just a vector. In this case, the dot product results in a vector of atomic dot products performed on each row from the matrix and this single vector. When inputs become a batch of inputs (a matrix), we need to perform the matrix product. It takes all of the combinations of rows from the left matrix and columns from the right matrix, performing the dot product on them and placing the results in an output array. Both arrays have the same shape, but, to perform the matrix product, the shape’s value from the index 1 of the first matrix and the index 0 of the second matrix must match — they don’t right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transpose.png](img/transpose.png \"Why we need to transpose to perform the matrix product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we transpose the second array, values of its shape swap their positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transpose-two.png](img/transpose-two.png \"After transposition, we can then perform the matrix product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at this from the perspective of the input and weights, we need to perform the dot product of each input and each weight set in all of their combinations. The dot product takes the row from the first array and the column from the second one, but currently the data in both arrays are row-aligned. Transposing the second array shapes the data to be column-aligned. The matrix product of inputs and transposed weights will result in a matrix containing all atomic dot products that we need to calculate. The resulting matrix consists of outputs of all the neurons after operations performed on each input sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "# Inputs, weights and biases\n",
    "inputs = [[1.0, 2.0, 3.0, 2.5], \n",
    "          [2.0, 5.0, -1.0, 2.0], \n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0], \n",
    "           [0.5, -0.91, 0.26, -0.5], \n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2.0, 3.0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we are a step forward when we model layer behavior on a batch of data. We could retain the current parameter order, but, as we’ll soon learn, it’s more useful to have a result consisting of a list of layer outputs per each sample than a list of neurons and their outputs sample-wise. We want the resulting array to be sample-related and not neuron-related as we’ll pass those samples further through the network, and the next layer will expect a batch of inputs. We can code this solution using Numpy now. We can perform _np.dot()_ on a plain Python list of lists as Numpy will convert them to matrices internally. We are converting weights ourselves though to perform transposition operation first, _.T_ in the code, as plain Python list of lists does not support it. Speaking of biases, we do not need to make it a NumPy array for the same reason — Numpy does internally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transposed-three.JPG](img/transposed-three.JPG \"Visualisation for inputs multiplied by the weights, plus the bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the neural network takes in a group of samples (inputs) and outputs a group of  predictions. If you’ve previously used any of the deep learning libraries (Tensorflow, Keras, PyTorch, etc), this is why you pass in a list of inputs (even if it’s just one feature set) you get a list of predictions, even if there’s only one prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
